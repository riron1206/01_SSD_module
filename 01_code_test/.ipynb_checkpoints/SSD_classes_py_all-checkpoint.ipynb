{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csvからアノテーションデータロードするSSD\n",
    "## 本番用（画像2万枚以上）で実行\n",
    "- ラベル付きで分類してみる\n",
    "- 編集したpyモジュールから実行する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ 学習の前準備 -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を tarin/val set に分ける\n",
    "- train:0.9, val:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "\n",
    "def split_train_val_set(train_dir, val_dir, train_images_path):\n",
    "    \"\"\"\n",
    "    指定ディレクトリの画像を tarin/val set に分けてコピーする\n",
    "    train:0.9, val:0.1 の割合でコピー\n",
    "    \"\"\"\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "    id_imgs = glob.glob(os.path.join(train_images_path, '*jpg'))\n",
    "    print('imgs:', len(id_imgs))\n",
    "    val_cnt = len(id_imgs)*0.1\n",
    "\n",
    "    count = 0\n",
    "    for img in id_imgs:\n",
    "        # val img copy\n",
    "        if count < val_cnt:\n",
    "            shutil.copyfile(img, os.path.join(val_dir, os.path.basename(img)))\n",
    "        # train img copy\n",
    "        else:\n",
    "            shutil.copyfile(img, os.path.join(train_dir, os.path.basename(img)))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs: 21258\n"
     ]
    }
   ],
   "source": [
    "# 本番用（画像2万枚以上）\n",
    "train_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\img_train_val\\train'\n",
    "val_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\img_train_val\\val'\n",
    "train_images_path = os.path.join(r'D:\\work\\AI_Edge_Contest\\object_detect\\origdata\\01.zip_expansion\\dtc_train_images')\n",
    "\n",
    "split_train_val_set(train_dir, val_dir, train_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アノテーションファイルをファイル出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チュートリアルのコードを元にした関数、クラス\n",
    "- https://signate.jp/competitions/142/tutorials/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_category_names(train_annotations_files):\n",
    "    \"\"\"\n",
    "    クラス名を取得\n",
    "    他に余計な処理あるが、これはチュートリアルのコードをコピーしたため\n",
    "    https://signate.jp/competitions/142/tutorials/9\n",
    "    \"\"\"\n",
    "    per_category = {}\n",
    "    per_image = []\n",
    "    for train_annotations_file in train_annotations_files:\n",
    "        with open(os.path.join(_train_annotations_path, train_annotations_file)) as f:\n",
    "            annotation = json.load(f)\n",
    "        labels = annotation['labels']\n",
    "        per_image.append(len(labels))\n",
    "        for label in labels:\n",
    "            if label['category'] in per_category:\n",
    "                per_category[label['category']]+=1\n",
    "            else:\n",
    "                per_category[label['category']]=1\n",
    "\n",
    "    category_names = ()\n",
    "    vals = ()\n",
    "    for category in per_category:\n",
    "        category_names+=(category,)\n",
    "        vals+=(per_category[category],)\n",
    "\n",
    "    print('category_names :' , category_names)\n",
    "    return category_names\n",
    "\n",
    "# class BboxDataset(GetterDataset):\n",
    "class BboxDataset():\n",
    "    def __init__(self, img_dir, annotation_dir, categories, img_ext='.jpg', annotation_ext='.json'):\n",
    "        super(BboxDataset, self).__init__()\n",
    "        \n",
    "        self.names = [i.split('.')[0] for i in os.listdir(img_dir)]\n",
    "        self.img_dir = img_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.categories = categories\n",
    "        self.img_ext = img_ext\n",
    "        self.annotation_ext = annotation_ext\n",
    "        #self.add_getter('img', self.get_image)\n",
    "        #self.add_getter(('bbox', 'label'), self.get_annotation)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def get_image(self, i):\n",
    "        name = self.names[i]\n",
    "        img_path = os.path.join(self.img_dir, name+self.img_ext)\n",
    "        #img = _read_image_pil(img_path, color=True)\n",
    "        img = Image.open(img_path)\n",
    "        img = np.asarray(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def get_annotation(self, i):\n",
    "        name = self.names[i]\n",
    "        annotation_path = os.path.join(self.annotation_dir, name+self.annotation_ext)\n",
    "        with open(annotation_path) as f:\n",
    "            annotation = json.load(f)\n",
    "        bbox = []\n",
    "        label = []\n",
    "        \n",
    "        for l in annotation['labels']:\n",
    "            if l['category'] in self.categories:\n",
    "                bb = l['box2d']\n",
    "                bbox.append([bb['y1'], bb['x1'], bb['y2'], bb['x2']])\n",
    "                label.append(self.categories.index(l['category']))\n",
    "        bbox = np.array(bbox).astype(np.float32)\n",
    "        label = np.array(label).astype(np.int32)\n",
    "        \n",
    "        return bbox, label, name\n",
    "\n",
    "def show_img_box(data, id):\n",
    "    \"\"\"クラスごとにBounding Boxの色を変える\"\"\"\n",
    "    img = data.get_image(id)\n",
    "    bbox, label, name = data.get_annotation(id)\n",
    "    for i in range(bbox.shape[0]):\n",
    "        b = bbox[i]\n",
    "        l = label[i]\n",
    "        #print(b, data.categories[l])\n",
    "        if l==0:\n",
    "            col = (255, 0, 0)\n",
    "        elif l==1:\n",
    "            col = (0, 255, 0)\n",
    "        elif l==2:\n",
    "            col = (0, 0, 255)\n",
    "        elif l==3:\n",
    "            col = (100, 255, 0)\n",
    "        elif l==4:\n",
    "            col = (100, 100, 0)\n",
    "        elif l==5:\n",
    "            col = (100, 100, 100)\n",
    "        elif l==6:\n",
    "            col = (50, 100, 100)\n",
    "        elif l==7:\n",
    "            col = (50, 100, 50)\n",
    "        elif l==8:\n",
    "            col = (50, 50, 100)\n",
    "        elif l==9:\n",
    "            col = (50, 50, 50)\n",
    "        cv2.rectangle(img, (b[1], b[0]), (b[3], b[2]), col, 5)\n",
    "        #cv2.rectangle(img, (int(b[1])-1, int(b[0])+10), (int(b[1])+150, int(b[0])-50), (255, 255, 255), -1)\n",
    "        cv2.putText(img, data.categories[l], (b[1], b[0]), cv2.FONT_HERSHEY_SIMPLEX, 2, col, 5)    \n",
    "    print(name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正解の座標（ファイル名, x, y, width, height）一覧のcsvファイルを作成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "def make_xywh_train_csv(train_annotations_files, data, xywh_train_csv_path='xywh_train.csv'):\n",
    "    \"\"\"\n",
    "    正解の座標（ファイル名, x, y, width, height）一覧のcsvファイルを作成する\n",
    "    \"\"\"\n",
    "    for id in range(len(train_annotations_files)):\n",
    "        #print(id)\n",
    "        bbox, label, name = data.get_annotation(id)\n",
    "        df = pd.DataFrame(bbox)\n",
    "        df.columns = ('y', 'x', 'y2', 'x2')\n",
    "        df['label_id'] = label\n",
    "        df['file_name'] = os.path.join(name+'.jpg')\n",
    "        #print(df)\n",
    "        if id == 0:\n",
    "            anno_df = df\n",
    "        else:\n",
    "            anno_df = pd.concat([anno_df, df])\n",
    "\n",
    "    anno_df_base = anno_df.copy()\n",
    "    anno_df_base.to_csv('anno_df_base.csv', sep=',', index=False)\n",
    "\n",
    "    # 'Car', 'Bicycle', 'Pedestrian', 'Signal', 'Signs', 'Truck' だけのレコードにする\n",
    "    anno_df = anno_df[(anno_df[\"label_id\"]==0) | (anno_df[\"label_id\"]==1) | (anno_df[\"label_id\"]==2) | (anno_df[\"label_id\"]==3) | (anno_df[\"label_id\"]==4) | (anno_df[\"label_id\"]==5)]\n",
    "\n",
    "    # ssd_training.py ではbackground_label_id=0 なのでCar クラスのid=0 をid=6 に置換する\n",
    "    # pandas置換例 df.col1[df.col1 == 2.] = 100. https://qiita.com/kazetof/items/992638be821a617b900a\n",
    "    anno_df.label_id[anno_df.label_id==0] = 6\n",
    "\n",
    "    print('anno_df\\n', anno_df.head())\n",
    "    anno_df['width'] = anno_df['x2'] - anno_df['x']\n",
    "    anno_df['height'] = anno_df['y2'] - anno_df['y']\n",
    "    #anno_df = anno_df.rename(columns={'x1': 'x', 'y1': 'y'})\n",
    "    print('anno_df\\n', anno_df.head())\n",
    "    # label_id列追加\n",
    "    anno_df = anno_df.loc[:,['file_name','x','y', 'width', 'height', 'label_id']]\n",
    "    anno_df['x'] = anno_df['x'].astype(np.int64)\n",
    "    anno_df['y'] = anno_df['y'].astype(np.int64)\n",
    "    anno_df['width'] = anno_df['width'].astype(np.int64)\n",
    "    anno_df['height'] = anno_df['height'].astype(np.int64)\n",
    "\n",
    "    # index 振り直し\n",
    "    anno_df = anno_df.reset_index(drop=True)\n",
    "    anno_df.to_csv(xywh_train_csv_path, sep=',', header=False, index=False)\n",
    "    print(xywh_train_csv_path+'\\n', anno_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_names : ('Car', 'Bicycle', 'Pedestrian', 'Signal', 'Signs', 'Truck', 'Bus', 'SVehicle', 'Motorbike', 'Train')\n",
      "anno_df\n",
      "        y      x     y2     x2  label_id        file_name\n",
      "0  573.0  925.0  628.0  995.0         6  train_00000.jpg\n",
      "0  620.0    0.0  691.0  165.0         1  train_00001.jpg\n",
      "1  581.0  142.0  746.0  211.0         2  train_00001.jpg\n",
      "2  555.0  369.0  731.0  432.0         2  train_00001.jpg\n",
      "3  560.0  772.0  620.0  806.0         2  train_00001.jpg\n",
      "anno_df\n",
      "        y      x     y2     x2  label_id        file_name  width  height\n",
      "0  573.0  925.0  628.0  995.0         6  train_00000.jpg   70.0    55.0\n",
      "0  620.0    0.0  691.0  165.0         1  train_00001.jpg  165.0    71.0\n",
      "1  581.0  142.0  746.0  211.0         2  train_00001.jpg   69.0   165.0\n",
      "2  555.0  369.0  731.0  432.0         2  train_00001.jpg   63.0   176.0\n",
      "3  560.0  772.0  620.0  806.0         2  train_00001.jpg   34.0    60.0\n",
      "xywh_train.csv\n",
      "          file_name    x    y  width  height  label_id\n",
      "0  train_00000.jpg  925  573     70      55         6\n",
      "1  train_00001.jpg    0  620    165      71         1\n",
      "2  train_00001.jpg  142  581     69     165         2\n",
      "3  train_00001.jpg  369  555     63     176         2\n",
      "4  train_00001.jpg  772  560     34      60         2\n"
     ]
    }
   ],
   "source": [
    "# 本番用（画像2万枚以上）\n",
    "_train_images_path = os.path.join(r'D:\\work\\AI_Edge_Contest\\object_detect\\origdata\\01.zip_expansion\\dtc_train_images')\n",
    "_train_annotations_path = os.path.join(r'D:\\work\\AI_Edge_Contest\\object_detect\\origdata\\01.zip_expansion\\dtc_train_annotations')\n",
    "train_annotations_files = os.listdir(_train_annotations_path)\n",
    "train_images_files = os.listdir(_train_images_path)\n",
    "\n",
    "category_names = get_category_names(train_annotations_files)\n",
    "data = BboxDataset(_train_images_path, _train_annotations_path, category_names)\n",
    "\n",
    "# 正解の座標（ファイル名, x, y, width, height）一覧のcsvファイルを作成\n",
    "make_xywh_train_csv(train_annotations_files, data, xywh_train_csv_path='xywh_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ 学習実行 -------------------------------------------\n",
    "## C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\01_google_drive_dl\\SSD_code_20190107\n",
    "## dtc_train_module.train_SSD300_NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_vgg\n",
      "Train Items : 19132\n",
      "Test  Items : 2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shingo\\Anaconda3\\envs\\tfgpu_py36_v2\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/100\n",
      " - 1962s - loss: 1.7606 - val_loss: 1.9137\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.91373, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 2/100\n",
      " - 1934s - loss: 1.7425 - val_loss: 1.8882\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.91373 to 1.88819, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 3/100\n",
      " - 1930s - loss: 1.7154 - val_loss: 1.8743\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.88819 to 1.87430, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 4/100\n",
      " - 1923s - loss: 1.6718 - val_loss: 1.8352\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.87430 to 1.83522, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 5/100\n",
      " - 1925s - loss: 1.6385 - val_loss: 1.8022\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.83522 to 1.80218, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 6/100\n",
      " - 2033s - loss: 1.6135 - val_loss: 1.7798\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.80218 to 1.77984, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 7/100\n",
      " - 1968s - loss: 1.5901 - val_loss: 1.7860\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      " - 1926s - loss: 1.5723 - val_loss: 1.7688\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.77984 to 1.76877, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 9/100\n",
      " - 1932s - loss: 1.5461 - val_loss: 1.7553\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.76877 to 1.75525, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 10/100\n",
      " - 1925s - loss: 1.5280 - val_loss: 1.7545\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.75525 to 1.75446, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 11/100\n",
      " - 1928s - loss: 1.5136 - val_loss: 1.7577\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      " - 1924s - loss: 1.5018 - val_loss: 1.7270\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.75446 to 1.72701, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 13/100\n",
      " - 1925s - loss: 1.4830 - val_loss: 1.7232\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.72701 to 1.72325, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 14/100\n",
      " - 1923s - loss: 1.4733 - val_loss: 1.7131\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.72325 to 1.71310, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 15/100\n",
      " - 1924s - loss: 1.4690 - val_loss: 1.7131\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      " - 1929s - loss: 1.4545 - val_loss: 1.7099\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.71310 to 1.70987, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 17/100\n",
      " - 1973s - loss: 1.4452 - val_loss: 1.7097\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.70987 to 1.70970, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 18/100\n",
      " - 1934s - loss: 1.4464 - val_loss: 1.6988\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.70970 to 1.69876, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 19/100\n",
      " - 1958s - loss: 1.4447 - val_loss: 1.7039\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/100\n",
      " - 1933s - loss: 1.4314 - val_loss: 1.6888\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.69876 to 1.68878, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 21/100\n",
      " - 1939s - loss: 1.4281 - val_loss: 1.7003\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      " - 1928s - loss: 1.4201 - val_loss: 1.6935\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      " - 1925s - loss: 1.4162 - val_loss: 1.6929\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      " - 1960s - loss: 1.4111 - val_loss: 1.6875\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.68878 to 1.68749, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 25/100\n",
      " - 1947s - loss: 1.4106 - val_loss: 1.6885\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      " - 1929s - loss: 1.4107 - val_loss: 1.6849\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.68749 to 1.68490, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 27/100\n",
      " - 1923s - loss: 1.4043 - val_loss: 1.6893\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      " - 1948s - loss: 1.4047 - val_loss: 1.6852\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      " - 1931s - loss: 1.4013 - val_loss: 1.6789\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.68490 to 1.67895, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 30/100\n",
      " - 1952s - loss: 1.3978 - val_loss: 1.6829\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      " - 1930s - loss: 1.3968 - val_loss: 1.6781\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.67895 to 1.67810, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 32/100\n",
      " - 1952s - loss: 1.3960 - val_loss: 1.6810\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      " - 1927s - loss: 1.3941 - val_loss: 1.6788\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n",
      " - 1927s - loss: 1.3924 - val_loss: 1.6789\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      " - 1955s - loss: 1.3893 - val_loss: 1.6784\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      " - 1931s - loss: 1.3915 - val_loss: 1.6773\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.67810 to 1.67725, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 37/100\n",
      " - 2006s - loss: 1.3906 - val_loss: 1.6806\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      " - 1964s - loss: 1.3895 - val_loss: 1.6778\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      " - 1950s - loss: 1.3885 - val_loss: 1.6779\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      " - 1957s - loss: 1.3883 - val_loss: 1.6767\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.67725 to 1.67671, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 41/100\n",
      " - 1961s - loss: 1.3880 - val_loss: 1.6776\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      " - 1932s - loss: 1.3912 - val_loss: 1.6772\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      " - 2179s - loss: 1.3871 - val_loss: 1.6774\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      " - 2175s - loss: 1.3845 - val_loss: 1.6765\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.67671 to 1.67645, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 45/100\n",
      " - 2071s - loss: 1.3899 - val_loss: 1.6758\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.67645 to 1.67576, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 46/100\n",
      " - 2008s - loss: 1.3859 - val_loss: 1.6752\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.67576 to 1.67517, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 47/100\n",
      " - 2006s - loss: 1.3863 - val_loss: 1.6749\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.67517 to 1.67486, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 48/100\n",
      " - 2002s - loss: 1.3870 - val_loss: 1.6746\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.67486 to 1.67460, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1997s - loss: 1.3869 - val_loss: 1.6754\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/100\n",
      " - 1978s - loss: 1.3874 - val_loss: 1.6759\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/100\n",
      " - 1974s - loss: 1.3822 - val_loss: 1.6761\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/100\n",
      " - 2063s - loss: 1.3825 - val_loss: 1.6753\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/100\n",
      " - 2005s - loss: 1.3824 - val_loss: 1.6752\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/100\n",
      " - 2006s - loss: 1.3801 - val_loss: 1.6744\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.67460 to 1.67441, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 55/100\n",
      " - 2009s - loss: 1.3864 - val_loss: 1.6744\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.67441 to 1.67438, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 56/100\n",
      " - 2002s - loss: 1.3858 - val_loss: 1.6749\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/100\n",
      " - 1977s - loss: 1.3833 - val_loss: 1.6750\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/100\n",
      " - 1972s - loss: 1.3837 - val_loss: 1.6759\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/100\n",
      " - 1965s - loss: 1.3788 - val_loss: 1.6744\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.67438 to 1.67436, saving model to D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5\n",
      "Epoch 60/100\n",
      " - 1976s - loss: 1.3844 - val_loss: 1.6751\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/100\n",
      " - 2016s - loss: 1.3845 - val_loss: 1.6751\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/100\n",
      " - 1978s - loss: 1.3817 - val_loss: 1.6753\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/100\n",
      " - 1977s - loss: 1.3785 - val_loss: 1.6748\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/100\n",
      " - 1989s - loss: 1.3841 - val_loss: 1.6750\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/100\n",
      " - 1991s - loss: 1.3833 - val_loss: 1.6754\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/100\n",
      " - 1984s - loss: 1.3807 - val_loss: 1.6751\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/100\n",
      " - 1985s - loss: 1.3818 - val_loss: 1.6750\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/100\n",
      " - 1986s - loss: 1.3818 - val_loss: 1.6748\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/100\n",
      " - 1988s - loss: 1.3835 - val_loss: 1.6752\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/100\n",
      " - 1992s - loss: 1.3866 - val_loss: 1.6750\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/100\n",
      " - 1990s - loss: 1.3845 - val_loss: 1.6749\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/100\n",
      " - 2010s - loss: 1.3762 - val_loss: 1.6751\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/100\n",
      " - 1991s - loss: 1.3807 - val_loss: 1.6751\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/100\n",
      " - 1993s - loss: 1.3798 - val_loss: 1.6750\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/100\n",
      " - 1991s - loss: 1.3856 - val_loss: 1.6750\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/100\n",
      " - 1994s - loss: 1.3803 - val_loss: 1.6749\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/100\n",
      " - 1990s - loss: 1.3823 - val_loss: 1.6749\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/100\n",
      " - 1988s - loss: 1.3824 - val_loss: 1.6748\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/100\n",
      " - 2038s - loss: 1.3851 - val_loss: 1.6748\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\01_google_drive_dl\\SSD_code_20190107\\dtc_train_module.py\u001b[0m in \u001b[0;36mtrain_SSD300_NAG\u001b[1;34m(master_file, train_dir, test_dir, model_path, load_weights_path, epochs, batch_size, base_lr, num_classes)\u001b[0m\n\u001b[0;32m    124\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                         validation_steps=gen.val_batches//batch_size)\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v2\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2192\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2194\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v2\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\01_google_drive_dl\\SSD_code_20190107')\n",
    "import dtc_train_module\n",
    "\n",
    "# 正解の座標（ファイル名, x, y, width, height）一覧のcsvファイル\n",
    "master_file = \"xywh_train.csv\"\n",
    "\n",
    "# 訓練用画像が入っているフォルダ\n",
    "train_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\img_train_val\\train'\n",
    "\n",
    "# 評価用画像が入っているフォルダ\n",
    "test_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\img_train_val\\val'\n",
    "\n",
    "# モデルファイルの保存先パス\n",
    "model_path = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5'\n",
    "\n",
    "# ロードする重みファイルのパス\n",
    "load_weights_path=r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes\\weight_ssd_best_epoch50_Cat_id_0.hdf5'\n",
    "\n",
    "# エポック数\n",
    "epochs = 100         \n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 10#50\n",
    "\n",
    "# 学習率初期値\n",
    "base_lr = 0.0006#1e-3#0.1 * batch_size / 128 だとlrでかすぎて？loss=nanになった。 1e-3 はいけたが \n",
    "\n",
    "# クラス数は7（背景とそれ以外6クラス）\n",
    "num_classes = 6+1   \n",
    "\n",
    "# SSDで学習\n",
    "dtc_train_module.train_SSD300_NAG(master_file, train_dir, test_dir, model_path\n",
    "                                  , load_weights_path=load_weights_path\n",
    "                                  , epochs=epochs\n",
    "                                  , batch_size=batch_size\n",
    "                                  , base_lr=base_lr\n",
    "                                  , num_classes=num_classes\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ 推論実行 -------------------------------------------\n",
    "## C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\01_google_drive_dl\\SSD_code_20190107  \n",
    "## dtc_predict_module.dtc_predict_py_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_vgg\n",
      "<keras.engine.training.Model object at 0x000001F8C8CFF0B8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6355/6355 [7:39:56<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7h 40min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\01_google_drive_dl\\SSD_code_20190107')\n",
    "%matplotlib inline\n",
    "import dtc_predict_module\n",
    "\n",
    "# テスト用画像が入っているフォルダ\n",
    "#predict_dir = r'C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\01_google_drive_dl\\SSD_code_20190107\\ssd_train' # 確認用\n",
    "predict_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\origdata\\01.zip_expansion\\dtc_test_images' # test全件\n",
    "\n",
    "# 予測画像出力先\n",
    "#predicted_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\predicted_images_test' # 確認用\n",
    "predicted_dir = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\predicted_images_test_all' # test全件\n",
    "\n",
    "# モデルファイルのパス\n",
    "model_path = r'D:\\work\\AI_Edge_Contest\\object_detect\\object_detection\\SSD_classes_py\\all\\weight_ssd_best.hdf5'\n",
    "\n",
    "# クラスid_クラス名\n",
    "dict = {0.0:\"other\", 1.0:\"Bicycle\", 2.0:\"Pedestrian\", 3.0:\"Signal\", 4.0:\"Signs\", 5.0:\"Truck\", 6.0:\"Car\"}\n",
    "\n",
    "# 検出するスコアの閾値\n",
    "conf_threshold=0.53#0.6 # 0.53 だと検出数が多すぎるためか提出結果エラーになる #0.6#0.78\n",
    "\n",
    "# 検出できるまで閾値下げるか\n",
    "#is_conf_threshold_down=False\n",
    "is_conf_threshold_down=True\n",
    "\n",
    "# SSDではない別の分類モデルで検出領域predictする場合\n",
    "# class_model = None　の場合は利用しない\n",
    "import keras\n",
    "#class_model = None\n",
    "class_model = keras.models.load_model(r'D:\\work\\AI_Edge_Contest\\object_detect\\classes\\trained_results\\class_0_5_model_InceptionResNetV2+SE_epoch10_from_02_keras_py\\finetuning.h5'\n",
    "                                      , compile=False)\n",
    "dict_class = {0.0:\"Car\", 1.0:\"Bicycle\", 2.0:\"Pedestrian\", 3.0:\"Signal\", 4.0:\"Signs\", 5.0:\"Truck\"}\n",
    "img_height = 331\n",
    "img_width = 331\n",
    "\n",
    "# 出力先に同名ファイルあればpredictしないかどうか Falseなら上書きしない\n",
    "is_overwrite=True\n",
    "\n",
    "# 検出結果の出力ファイルあれば消しとく\n",
    "import os\n",
    "if os.path.exists('pred.csv'):\n",
    "    os.remove('pred.csv')\n",
    "if os.path.exists('pred.json'):\n",
    "    os.remove('pred.json')\n",
    "\n",
    "dtc_predict_module.dtc_predict_py_edit(predict_dir\n",
    "                                       , predicted_dir\n",
    "                                       , dict\n",
    "                                       , model_path\n",
    "                                       , conf_threshold=conf_threshold\n",
    "                                       , is_conf_threshold_down=is_conf_threshold_down\n",
    "                                       , class_model=class_model\n",
    "                                       , dict_class=dict_class\n",
    "                                       , img_height=img_height, img_width=img_width\n",
    "                                       , is_overwrite=is_overwrite\n",
    "                                       , max_box=100\n",
    "                                       , min_top_indices=0 # 0なら最低でも1件だけ検出\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>conf</th>\n",
       "      <th>label_name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x+w</th>\n",
       "      <th>y+h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0000.jpg</td>\n",
       "      <td>0.996634</td>\n",
       "      <td>Car</td>\n",
       "      <td>1538</td>\n",
       "      <td>597</td>\n",
       "      <td>1854</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_0000.jpg</td>\n",
       "      <td>0.900444</td>\n",
       "      <td>Car</td>\n",
       "      <td>1153</td>\n",
       "      <td>576</td>\n",
       "      <td>1345</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_0000.jpg</td>\n",
       "      <td>0.853855</td>\n",
       "      <td>Truck</td>\n",
       "      <td>1389</td>\n",
       "      <td>557</td>\n",
       "      <td>1542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_0000.jpg</td>\n",
       "      <td>0.850350</td>\n",
       "      <td>Truck</td>\n",
       "      <td>747</td>\n",
       "      <td>520</td>\n",
       "      <td>1075</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_0000.jpg</td>\n",
       "      <td>0.795689</td>\n",
       "      <td>Truck</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>198</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_names      conf label_name     x    y   x+w  y+h\n",
       "0  test_0000.jpg  0.996634        Car  1538  597  1854  783\n",
       "1  test_0000.jpg  0.900444        Car  1153  576  1345  652\n",
       "2  test_0000.jpg  0.853855      Truck  1389  557  1542  650\n",
       "3  test_0000.jpg  0.850350      Truck   747  520  1075  650\n",
       "4  test_0000.jpg  0.795689      Truck     0  548   198  641"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pred.csv', sep='\\t')\n",
    "df.head()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
