{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csvからアノテーションデータロードするSSD\n",
    "## テスト用（画像10枚）で実行\n",
    "- ラベル付きで分類してみる\n",
    "- 編集したpyモジュールから実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "output_dir = r'output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ 学習の前準備 -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を tarin/val set に分ける\n",
    "- train:0.9, val:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "\n",
    "def split_train_val_set(train_dir, val_dir, train_images_path):\n",
    "    \"\"\"\n",
    "    指定ディレクトリの画像を tarin/val set に分けてコピーする\n",
    "    train:0.9, val:0.1 の割合でコピー\n",
    "    \"\"\"\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "    id_imgs = glob.glob(os.path.join(train_images_path, '*jpg'))\n",
    "    print('imgs:', len(id_imgs))\n",
    "    val_cnt = len(id_imgs)*0.1\n",
    "\n",
    "    count = 0\n",
    "    for img in id_imgs:\n",
    "        # val img copy\n",
    "        if count < val_cnt:\n",
    "            shutil.copyfile(img, os.path.join(val_dir, os.path.basename(img)))\n",
    "        # train img copy\n",
    "        else:\n",
    "            shutil.copyfile(img, os.path.join(train_dir, os.path.basename(img)))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs: 10\n"
     ]
    }
   ],
   "source": [
    "# テスト用（画像10枚）\n",
    "train_dir = r'01_test_data\\ssd_train\\train' \n",
    "val_dir = r'01_test_data\\ssd_train\\valid'\n",
    "train_images_path = os.path.join(r'01_test_data\\ssd_train_org\\img')\n",
    "\n",
    "split_train_val_set(train_dir, val_dir, train_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アノテーションファイルをファイル出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チュートリアルのコードを元にした関数、クラス\n",
    "- https://signate.jp/competitions/142/tutorials/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_category_names(train_annotations_path, train_annotations_files):\n",
    "    \"\"\"\n",
    "    クラス名を取得\n",
    "    他に余計な処理あるが、これはチュートリアルのコードをコピーしたため\n",
    "    https://signate.jp/competitions/142/tutorials/9\n",
    "    \"\"\"\n",
    "    per_category = {}\n",
    "    per_image = []\n",
    "    for train_annotations_file in train_annotations_files:\n",
    "        with open(os.path.join(train_annotations_path, train_annotations_file)) as f:\n",
    "            annotation = json.load(f)\n",
    "        labels = annotation['labels']\n",
    "        per_image.append(len(labels))\n",
    "        for label in labels:\n",
    "            if label['category'] in per_category:\n",
    "                per_category[label['category']]+=1\n",
    "            else:\n",
    "                per_category[label['category']]=1\n",
    "\n",
    "    category_names = ()\n",
    "    vals = ()\n",
    "    for category in per_category:\n",
    "        category_names+=(category,)\n",
    "        vals+=(per_category[category],)\n",
    "\n",
    "    print('category_names :' , category_names)\n",
    "    return category_names\n",
    "\n",
    "# class BboxDataset(GetterDataset):\n",
    "class BboxDataset():\n",
    "    def __init__(self, img_dir, annotation_dir, categories, img_ext='.jpg', annotation_ext='.json'):\n",
    "        super(BboxDataset, self).__init__()\n",
    "        \n",
    "        self.names = [i.split('.')[0] for i in os.listdir(img_dir)]\n",
    "        self.img_dir = img_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.categories = categories\n",
    "        self.img_ext = img_ext\n",
    "        self.annotation_ext = annotation_ext\n",
    "        #self.add_getter('img', self.get_image)\n",
    "        #self.add_getter(('bbox', 'label'), self.get_annotation)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def get_image(self, i):\n",
    "        name = self.names[i]\n",
    "        img_path = os.path.join(self.img_dir, name+self.img_ext)\n",
    "        #img = _read_image_pil(img_path, color=True)\n",
    "        img = Image.open(img_path)\n",
    "        img = np.asarray(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def get_annotation(self, i):\n",
    "        name = self.names[i]\n",
    "        annotation_path = os.path.join(self.annotation_dir, name+self.annotation_ext)\n",
    "        with open(annotation_path) as f:\n",
    "            annotation = json.load(f)\n",
    "        bbox = []\n",
    "        label = []\n",
    "        \n",
    "        for l in annotation['labels']:\n",
    "            if l['category'] in self.categories:\n",
    "                bb = l['box2d']\n",
    "                bbox.append([bb['y1'], bb['x1'], bb['y2'], bb['x2']])\n",
    "                label.append(self.categories.index(l['category']))\n",
    "        bbox = np.array(bbox).astype(np.float32)\n",
    "        label = np.array(label).astype(np.int32)\n",
    "        \n",
    "        return bbox, label, name\n",
    "\n",
    "def show_img_box(data, id):\n",
    "    \"\"\"クラスごとにBounding Boxの色を変える\"\"\"\n",
    "    img = data.get_image(id)\n",
    "    bbox, label, name = data.get_annotation(id)\n",
    "    for i in range(bbox.shape[0]):\n",
    "        b = bbox[i]\n",
    "        l = label[i]\n",
    "        #print(b, data.categories[l])\n",
    "        if l==0:\n",
    "            col = (255, 0, 0)\n",
    "        elif l==1:\n",
    "            col = (0, 255, 0)\n",
    "        elif l==2:\n",
    "            col = (0, 0, 255)\n",
    "        elif l==3:\n",
    "            col = (100, 255, 0)\n",
    "        elif l==4:\n",
    "            col = (100, 100, 0)\n",
    "        elif l==5:\n",
    "            col = (100, 100, 100)\n",
    "        elif l==6:\n",
    "            col = (50, 100, 100)\n",
    "        elif l==7:\n",
    "            col = (50, 100, 50)\n",
    "        elif l==8:\n",
    "            col = (50, 50, 100)\n",
    "        elif l==9:\n",
    "            col = (50, 50, 50)\n",
    "        cv2.rectangle(img, (b[1], b[0]), (b[3], b[2]), col, 5)\n",
    "        #cv2.rectangle(img, (int(b[1])-1, int(b[0])+10), (int(b[1])+150, int(b[0])-50), (255, 255, 255), -1)\n",
    "        cv2.putText(img, data.categories[l], (b[1], b[0]), cv2.FONT_HERSHEY_SIMPLEX, 2, col, 5)    \n",
    "    print(name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正解の座標（ファイル名, x, y, width, height）とラベルの一覧のcsvファイルを作成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "def make_xywh_train_csv(output_dir, train_annotations_files, data, xywh_train_csv_path='xywh_train.csv'):\n",
    "    \"\"\"\n",
    "    正解の座標（ファイル名, x, y, width, height）一覧のcsvファイルを作成する\n",
    "    \"\"\"\n",
    "    for id in range(len(train_annotations_files)):\n",
    "        #print(id)\n",
    "        bbox, label, name = data.get_annotation(id)\n",
    "        df = pd.DataFrame(bbox)\n",
    "        df.columns = ('y', 'x', 'y2', 'x2')\n",
    "        df['label_id'] = label\n",
    "        df['file_name'] = os.path.join(name+'.jpg')\n",
    "        #print(df)\n",
    "        if id == 0:\n",
    "            anno_df = df\n",
    "        else:\n",
    "            anno_df = pd.concat([anno_df, df])\n",
    "\n",
    "    anno_df_base = anno_df.copy()\n",
    "    anno_df_base.to_csv(os.path.join(output_dir, 'anno_df_base.csv'), sep=',', index=False)\n",
    "\n",
    "    # 'Car', 'Bicycle', 'Pedestrian', 'Signal', 'Signs', 'Truck' だけのレコードにする\n",
    "    anno_df = anno_df[(anno_df[\"label_id\"]==0) | (anno_df[\"label_id\"]==1) | (anno_df[\"label_id\"]==2) | (anno_df[\"label_id\"]==3) | (anno_df[\"label_id\"]==4) | (anno_df[\"label_id\"]==5)]\n",
    "\n",
    "    # ssd_training.py ではbackground_label_id=0 なのでCar クラスのid=0 をid=6 に置換する\n",
    "    # pandas置換例 df.col1[df.col1 == 2.] = 100. https://qiita.com/kazetof/items/992638be821a617b900a\n",
    "    anno_df.label_id[anno_df.label_id==0] = 6\n",
    "\n",
    "    print('anno_df\\n', anno_df.head())\n",
    "    anno_df['width'] = anno_df['x2'] - anno_df['x']\n",
    "    anno_df['height'] = anno_df['y2'] - anno_df['y']\n",
    "    #anno_df = anno_df.rename(columns={'x1': 'x', 'y1': 'y'})\n",
    "    print('anno_df\\n', anno_df.head())\n",
    "    # label_id列追加\n",
    "    anno_df = anno_df.loc[:,['file_name','x','y', 'width', 'height', 'label_id']]\n",
    "    anno_df['x'] = anno_df['x'].astype(np.int64)\n",
    "    anno_df['y'] = anno_df['y'].astype(np.int64)\n",
    "    anno_df['width'] = anno_df['width'].astype(np.int64)\n",
    "    anno_df['height'] = anno_df['height'].astype(np.int64)\n",
    "\n",
    "    # index 振り直し\n",
    "    anno_df = anno_df.reset_index(drop=True)\n",
    "    anno_df.to_csv(xywh_train_csv_path, sep=',', header=False, index=False)\n",
    "    print(xywh_train_csv_path+'\\n', anno_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_names : ('Car', 'Bicycle', 'Pedestrian', 'Signal', 'Signs', 'Truck')\n",
      "anno_df\n",
      "        y      x     y2     x2  label_id        file_name\n",
      "0  573.0  925.0  628.0  995.0         6  train_00000.jpg\n",
      "0  620.0    0.0  691.0  165.0         1  train_00001.jpg\n",
      "1  581.0  142.0  746.0  211.0         2  train_00001.jpg\n",
      "2  555.0  369.0  731.0  432.0         2  train_00001.jpg\n",
      "3  560.0  772.0  620.0  806.0         2  train_00001.jpg\n",
      "anno_df\n",
      "        y      x     y2     x2  label_id        file_name  width  height\n",
      "0  573.0  925.0  628.0  995.0         6  train_00000.jpg   70.0    55.0\n",
      "0  620.0    0.0  691.0  165.0         1  train_00001.jpg  165.0    71.0\n",
      "1  581.0  142.0  746.0  211.0         2  train_00001.jpg   69.0   165.0\n",
      "2  555.0  369.0  731.0  432.0         2  train_00001.jpg   63.0   176.0\n",
      "3  560.0  772.0  620.0  806.0         2  train_00001.jpg   34.0    60.0\n",
      "output\\xywh_train_small.csv\n",
      "          file_name    x    y  width  height  label_id\n",
      "0  train_00000.jpg  925  573     70      55         6\n",
      "1  train_00001.jpg    0  620    165      71         1\n",
      "2  train_00001.jpg  142  581     69     165         2\n",
      "3  train_00001.jpg  369  555     63     176         2\n",
      "4  train_00001.jpg  772  560     34      60         2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shingo\\Anaconda3\\envs\\tfgpu_py36_v2\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# テスト用（画像10枚）\n",
    "train_images_path = os.path.join(r'01_test_data\\ssd_train_org\\img')\n",
    "train_images_files = os.listdir(train_images_path)\n",
    "\n",
    "# アノテーションのjsonディレクトリ\n",
    "train_annotations_path = os.path.join(r'01_test_data\\ssd_train_org\\json')\n",
    "train_annotations_files = os.listdir(train_annotations_path)\n",
    "\n",
    "category_names = get_category_names(train_annotations_path, train_annotations_files)\n",
    "data = BboxDataset(train_images_path, train_annotations_path, category_names)\n",
    "\n",
    "# 正解の座標（ファイル名, x, y, width, height）一覧のcsvファイルを作成\n",
    "make_xywh_train_csv(output_dir, train_annotations_files, data, xywh_train_csv_path=os.path.join(output_dir, 'xywh_train_small.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ 学習実行 -------------------------------------------\n",
    "## C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\AI_Edge_Contest\\object_detection\\SSD_classes_py\\all_SSD_module\\SSD\n",
    "## dtc_train_module.train_SSD300_NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_vgg\n",
      "create_model ok\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 3 and 16. Shapes are [3,3,512,12] and [16,512,3,3]. for 'Assign_43' (op: 'Assign') with input shapes: [3,3,512,12], [16,512,3,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 16. Shapes are [3,3,512,12] and [16,512,3,3]. for 'Assign_43' (op: 'Assign') with input shapes: [3,3,512,12], [16,512,3,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\tfgpu_py36_work\\01_SSD_module\\SSD\\dtc_train_module.py\u001b[0m in \u001b[0;36mtrain_SSD300_NAG\u001b[1;34m(master_file, train_dir, test_dir, model_path, load_weights_path, epochs, batch_size, base_lr, num_classes, callback)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'create_model ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_weights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_weights ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   2651\u001b[0m                 load_weights_from_hdf5_group_by_name(\n\u001b[0;32m   2652\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskip_mismatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2653\u001b[1;33m                     reshape=reshape)\n\u001b[0m\u001b[0;32m   2654\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2655\u001b[0m                 load_weights_from_hdf5_group(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[1;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   3466\u001b[0m                                             weight_values[i]))\n\u001b[0;32m   3467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3468\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2366\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2367\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2368\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2369\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2370\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \"\"\"\n\u001b[1;32m--> 615\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    281\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    282\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    284\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m     58\u001b[0m         \u001b[1;34m\"Assign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfgpu_py36_v3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 16. Shapes are [3,3,512,12] and [16,512,3,3]. for 'Assign_43' (op: 'Assign') with input shapes: [3,3,512,12], [16,512,3,3]."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'../SSD')\n",
    "import dtc_train_module\n",
    "\n",
    "# 正解の座標（ファイル名, x, y, width, height）一覧のcsvファイル\n",
    "master_file = os.path.join(output_dir, 'xywh_train_small.csv')\n",
    "\n",
    "# 訓練用画像が入っているフォルダ\n",
    "train_dir = r'01_test_data\\ssd_train\\train'\n",
    "\n",
    "# 評価用画像が入っているフォルダ\n",
    "test_dir = r'01_test_data\\ssd_train\\valid'\n",
    "\n",
    "# モデルファイルの保存先パス\n",
    "model_path = os.path.join(output_dir, 'weight_ssd_best.hdf5')\n",
    "\n",
    "# 重みファイルのパス\n",
    "#load_weights_path=r'../SSD/weight_ssd_best.hdf5'\n",
    "load_weights_path=r'../SSD/weights_SSD300.hdf5'\n",
    "#load_weights_path=r'C:\\Users\\shingo\\Git\\ssd_keras_pierluigiferrari\\VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.h5' # 実行不可能\n",
    "\n",
    "epochs = 1#50       # エポック数\n",
    "batch_size = 1#50 # バッチサイズ\n",
    "\n",
    "# base_lr = 1e-3, 0.005, 0.0005 はいける →結局 1e-3 が一番よさげ\n",
    "# base_lr = 0.01, 0.05 はloss=nan になった\n",
    "# 重みファイル替えてもlr = 0.01 はloss=nan\n",
    "base_lr = 1e-3    # 学習率初期値\n",
    "\n",
    "num_classes = 6+1   # クラス数は7（背景とそれ以外6クラス）\n",
    "\n",
    "# SSDで学習\n",
    "dtc_train_module.train_SSD300_NAG(master_file, train_dir, test_dir, model_path\n",
    "                                  , load_weights_path=load_weights_path\n",
    "                                  , epochs=epochs\n",
    "                                  , batch_size=batch_size\n",
    "                                  , base_lr=base_lr\n",
    "                                  , num_classes=num_classes\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ 推論実行 -------------------------------------------\n",
    "## C:\\Users\\shingo\\jupyter_notebook\\tfgpu_py36_work\\AI_Edge_Contest\\object_detection\\SSD_classes_py\\all_SSD_module\\SSD  \n",
    "## dtc_predict_module.dtc_predict_py_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_vgg\n",
      "<keras.engine.training.Model object at 0x0000024AB10107F0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'../SSD')\n",
    "%matplotlib inline\n",
    "import dtc_predict_module\n",
    "\n",
    "# テスト用画像が入っているフォルダ\n",
    "predict_dir = r'01_test_data\\ssd_test'\n",
    "\n",
    "# 予測画像出力先\n",
    "predicted_dir = os.path.join(output_dir, 'predicted_images_test_all')\n",
    "\n",
    "# モデルファイルのパス\n",
    "model_path = os.path.join(output_dir, 'weight_ssd_best.hdf5')\n",
    "\n",
    "# クラスid_クラス名\n",
    "dict = {0.0:\"other\", 1.0:\"Bicycle\", 2.0:\"Pedestrian\", 3.0:\"Signal\", 4.0:\"Signs\", 5.0:\"Truck\", 6.0:\"Car\"}\n",
    "\n",
    "# 検出するスコアの閾値\n",
    "conf_threshold=0.53#0.6 # 0.53 だと検出数が多すぎるためか提出結果エラーになる #0.6#0.78\n",
    "\n",
    "# 検出できるまで閾値下げるか\n",
    "#is_conf_threshold_down=False\n",
    "is_conf_threshold_down=True\n",
    "\n",
    "# SSDではない別の分類モデルで検出領域predictする場合\n",
    "# class_model = None　の場合は利用しない\n",
    "import keras\n",
    "#class_model = None\n",
    "class_model = keras.models.load_model(r'D:\\work\\AI_Edge_Contest\\object_detect\\classes\\trained_results\\class_0_5_model_InceptionResNetV2+SE_epoch10_from_02_keras_py\\finetuning.h5'\n",
    "                                      , compile=False)\n",
    "dict_class = {0.0:\"Car\", 1.0:\"Bicycle\", 2.0:\"Pedestrian\", 3.0:\"Signal\", 4.0:\"Signs\", 5.0:\"Truck\"}\n",
    "img_height = 331\n",
    "img_width = 331\n",
    "\n",
    "# 出力先に同名ファイルあればpredictしないかどうか Falseなら上書きしない\n",
    "is_overwrite=True\n",
    "\n",
    "# 検出結果の出力ファイルあれば消しとく\n",
    "import os\n",
    "if os.path.exists(os.path.join(output_dir, 'pred.csv')):\n",
    "    os.remove(os.path.join(output_dir, 'pred.csv'))\n",
    "if os.path.exists(os.path.join(output_dir, 'pred.json')):\n",
    "    os.remove(os.path.join(output_dir, 'pred.json'))\n",
    "\n",
    "dtc_predict_module.dtc_predict_py_edit(predict_dir\n",
    "                                       , predicted_dir\n",
    "                                       , dict\n",
    "                                       , model_path\n",
    "                                       , conf_threshold=conf_threshold\n",
    "                                       , is_conf_threshold_down=is_conf_threshold_down\n",
    "                                       , class_model=class_model\n",
    "                                       , dict_class=dict_class\n",
    "                                       , img_height=img_height, img_width=img_width\n",
    "                                       , is_overwrite=is_overwrite\n",
    "                                       , max_box=100\n",
    "                                       , min_top_indices=0 # 0なら最低でも1件だけ検出\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>conf</th>\n",
       "      <th>label_name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x+w</th>\n",
       "      <th>y+h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_00010.jpg</td>\n",
       "      <td>0.734418</td>\n",
       "      <td>Signal</td>\n",
       "      <td>347</td>\n",
       "      <td>501</td>\n",
       "      <td>1608</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_00010.jpg</td>\n",
       "      <td>0.685293</td>\n",
       "      <td>Bicycle</td>\n",
       "      <td>446</td>\n",
       "      <td>85</td>\n",
       "      <td>602</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_00010.jpg</td>\n",
       "      <td>0.684101</td>\n",
       "      <td>Signs</td>\n",
       "      <td>694</td>\n",
       "      <td>809</td>\n",
       "      <td>1028</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_00010.jpg</td>\n",
       "      <td>0.565666</td>\n",
       "      <td>Signs</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1025</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_00010.jpg</td>\n",
       "      <td>0.539123</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>1246</td>\n",
       "      <td>611</td>\n",
       "      <td>1280</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_names      conf  label_name     x    y   x+w   y+h\n",
       "0  train_00010.jpg  0.734418      Signal   347  501  1608  1215\n",
       "1  train_00010.jpg  0.685293     Bicycle   446   85   602   209\n",
       "2  train_00010.jpg  0.684101       Signs   694  809  1028  1212\n",
       "3  train_00010.jpg  0.565666       Signs    25    6  1025   915\n",
       "4  train_00010.jpg  0.539123  Pedestrian  1246  611  1280   690"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join(output_dir, 'pred.csv'), sep='\\t')\n",
    "df.head()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
